{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, os, random, time, datetime\n",
    "from pathlib import Path\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from meteocalc import feels_like, Temp\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign_building_site0 = [0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
    "                        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
    "                        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
    "                        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
    "                        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
    "                        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
    "                        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
    "                        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
    "                       104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test, Building Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df = pd.read_csv('train.csv', parse_dates=['timestamp'])\n",
    "test_df = pd.read_csv('test.csv', parse_dates=['timestamp'])\n",
    "\n",
    "weather_train_df = pd.read_csv('weather_train.csv', parse_dates=['timestamp'])\n",
    "weather_test_df = pd.read_csv('weather_test.csv', parse_dates=['timestamp'])\n",
    "\n",
    "building_meta_df = pd.read_csv('building_metadata.csv')\n",
    "\n",
    "rows_to_drop = pd.read_csv('rows_to_drop.csv')\n",
    "faulty_idxs = pd.read_csv('faulty_idxs.csv')\n",
    "bidencoding = pd.read_csv('bidencoding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions: Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessDf(df):\n",
    "    \n",
    "    # Hourly\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 23)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 23)\n",
    "    \n",
    "    # Weekly\n",
    "    df['dayofweek'] = df['timestamp'].dt.dayofweek\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 6)\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 6)\n",
    "    df['isweekend'] = np.where(df['dayofweek'] > 4, True, False)\n",
    "    \n",
    "    # Monthly\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    \n",
    "    # Seasonal\n",
    "    temp = pd.Series([0,0,0,1,1,1,1,1,1,0,0,0])\n",
    "    temp.index += 1\n",
    "    df['season'] = df.month.map(temp)\n",
    "    \n",
    "    # Target Log Transformation\n",
    "    train_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])\n",
    "    \n",
    "    # Building Target Encoding\n",
    "    df_group = train_df.groupby(['building_id'])['meter_reading_log1p']\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_Q1 = df_group.quantile(0.25).astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_Q3 = df_group.quantile(0.75).astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "    df['building__mean'] = df['building_id'].map(building_mean)\n",
    "    df['building__median'] = df['building_id'].map(building_median)\n",
    "    df['building__min'] = df['building_id'].map(building_min)\n",
    "    df['building__max'] = df['building_id'].map(building_max)\n",
    "    df['building__range'] = df['building__max'] - df['building__min']\n",
    "    df['building__std'] = df['building_id'].map(building_std)\n",
    "    df['building__count'] = df['building_id'].map(bidencoding[bidencoding.columns[0]])\n",
    "    df['building__Q1'] = df['building_id'].map(building_Q1)\n",
    "    df['building__Q3'] = df['building_id'].map(building_Q3)\n",
    "    df['building__IQR'] = df['building__Q1'] - df['building__Q3']\n",
    "    del df_group; gc.collect()\n",
    "    \n",
    "    # Hourly Target Encoding\n",
    "    df_group = train_df.groupby('hour')['meter_reading_log1p']\n",
    "    hour_mean = df_group.mean().astype(np.float16)\n",
    "    hour_min = df_group.min().astype(np.float16)\n",
    "    hour_max = df_group.max().astype(np.float16)\n",
    "    hour_std = df_group.std().astype(np.float16)\n",
    "    df['hour_mean'] = df['hour'].map(hour_mean)\n",
    "    df['hour_min'] = df['hour'].map(hour_min)\n",
    "    df['hour_max'] = df['hour'].map(hour_max)\n",
    "    df['hour_std'] = df['hour'].map(hour_std)\n",
    "    del df_group; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessWeather_lag(df, window=3):\n",
    "    \n",
    "    group_df = df.groupby('site_id')\n",
    "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "            'precip_depth_1_hr', 'sea_level_pressure',\n",
    "            'wind_speed', 'feels_like_temperature']\n",
    "    \n",
    "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
    "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "    lag_Q1 = rolled.quantile(0.25).reset_index().astype(np.float16)\n",
    "    lag_skew = rolled.skew().reset_index().astype(np.float16)\n",
    "    \n",
    "    for col in cols:\n",
    "        df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        df[f'{col}_max_lag{window}'] = lag_max[col]\n",
    "        df[f'{col}_std_lag{window}'] = lag_std[col]\n",
    "        df[f'{col}_Q1_lag{window}'] = lag_Q1[col]\n",
    "        df[f'{col}_skew_lag{window}'] = lag_skew[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessWeather(df):\n",
    "    \n",
    "    # Cyclical Wind Direction\n",
    "    df['wind_direction_sin'] = np.sin((2 * np.pi * df['wind_direction']) / 360)\n",
    "    df['wind_direction_cos'] = np.cos((2 * np.pi * df['wind_direction']) / 360)\n",
    "    \n",
    "    # Relative Humidity\n",
    "    E = 6.11 * 10.0 ** (7.5 * df['dew_temperature'] / (237.7 + df['dew_temperature']))\n",
    "    Es = 6.11 * 10.0 ** (7.5 * df['air_temperature'] / (237.7 + df['air_temperature']))    \n",
    "    df['relative_humidity'] = (E / Es) * 100\n",
    "    del E, Es; gc.collect()\n",
    "    \n",
    "    # Feels-Like Temperature\n",
    "    temp = np.zeros((df.air_temperature.shape[0], 2))\n",
    "    for i,j in enumerate(df.air_temperature.index):\n",
    "        assert i == j, print('feels like temperature: index doesnt equal range')\n",
    "        temp[i, 0] = j\n",
    "        temp[i, 1] = feels_like(Temp(df.air_temperature[i], 'c'), df.relative_humidity[i], df.wind_speed[i]).c\n",
    "    df['test_1'] = temp[:, 0]\n",
    "    df['test_2'] = temp[:, 1]\n",
    "    assert ((df.test_1.reset_index()['index'] == df.test_1).astype(int).sum() == df.test_1.shape[0]), print('oops')\n",
    "    df['feels_like_temperature'] = df['test_2']\n",
    "    del df['test_1'], df['test_2']; gc.collect()\n",
    "    \n",
    "    # Discomfort Index\n",
    "    _1 = 0.81 * df['air_temperature']\n",
    "    _2 = 0.01 * df['relative_humidity']\n",
    "    _3 = 0.99 * df['air_temperature']\n",
    "    df['discomfort_index'] = _1 + (_2 * (_3 - 14.3)) + 46.3\n",
    "    del _1, _2, _3; gc.collect()\n",
    "    \n",
    "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "            'precip_depth_1_hr', 'sea_level_pressure',\n",
    "            'wind_direction_sin', 'wind_direction_cos',\n",
    "            'wind_speed', 'feels_like_temperature', 'site_id']\n",
    "    \n",
    "    # Time-Series Interpolation (Linear and 3rd-Order)\n",
    "    temp_1 = df.groupby('site_id').apply(lambda group: group.interpolate(method='linear', limit_direction='both'))\n",
    "    temp_2 = df.groupby('site_id').apply(lambda group: group.interpolate(method='polynomial', order=3, limit_direction='both'))\n",
    "    temp = (temp_1[cols] + temp_2[cols]) / 2\n",
    "    assert df[cols].shape[1] == temp.shape[1]\n",
    "    df[cols] = temp\n",
    "    del temp_1, temp_2\n",
    "    for col in cols:\n",
    "        temp[col].fillna(temp[col].median(), inplace=True)\n",
    "    \n",
    "    # Oneth Decimal Value\n",
    "    modify = np.vectorize(math.modf)\n",
    "    oneth, tenth = modify(df['feels_like_temperature'] / 10)\n",
    "    df['feel_oneth'] = oneth * 10\n",
    "    \n",
    "    # Past Values\n",
    "    for col in (set(cols) - {'site_id'}):\n",
    "        df['{}_isnan'.format(col)] = df[col].isnull().astype(int)\n",
    "        df[f'{col}_shift_12'] = df[col].shift(12)\n",
    "        df[f'{col}_shift_24'] = df[col].shift(24)\n",
    "        df[f'{col}_shift_48'] = df[col].shift(48)\n",
    "        df[f'{col}_shift_72'] = df[col].shift(72)\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Meta-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessBuilding(df):\n",
    "    df['square_feet'] = np.log1p(df['square_feet'])\n",
    "    df['sqft-x-yearbuilt'] = df['square_feet'] / df['year_built']\n",
    "    df['sqft_*_floorcount'] = df['square_feet'] * df['floor_count']\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data Timestamp Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dtypes = {\n",
    "    'site_id': np.uint8,\n",
    "    'air_temperature': np.float32,\n",
    "    'cloud_coverage': np.float32,\n",
    "    'dew_temperature': np.float32,\n",
    "    'precip_depth_1_hr': np.float32,\n",
    "    'sea_level_pressure': np.float32,\n",
    "    'wind_direction': np.float32,\n",
    "    'wind_speed': np.float32,\n",
    "}\n",
    "\n",
    "weather_train = pd.read_csv('weather_train.csv',\n",
    "                            dtype=_dtypes,\n",
    "                            parse_dates=['timestamp'])\n",
    "weather_test = pd.read_csv('weather_test.csv',\n",
    "                           dtype=_dtypes,\n",
    "                           parse_dates=['timestamp'])\n",
    "weather = pd.concat([weather_train, weather_test], ignore_index=True)\n",
    "del _dtypes, weather_train, weather_test; gc.collect()\n",
    "\n",
    "_key = ['site_id', 'timestamp']\n",
    "\n",
    "temp = weather[_key + ['air_temperature']].drop_duplicates(subset=_key).sort_values(by=_key).copy()\n",
    "temp['temp_rank'] = temp.groupby(['site_id', temp.timestamp.dt.date])['air_temperature'].rank('average')\n",
    "\n",
    "temp = temp.groupby(['site_id', temp.timestamp.dt.hour])['temp_rank'].mean().unstack(level=1)\n",
    "temp = pd.Series(temp.values.argmax(axis=1) - 14)\n",
    "temp.index.name = 'site_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_align(df, temp):\n",
    "    \n",
    "    df['offset'] = df.site_id.map(temp)\n",
    "    df['timestamp_aligned'] = (df.timestamp - pd.to_timedelta(df.offset, unit='H'))\n",
    "    df['timestamp'] = df['timestamp_aligned']\n",
    "    \n",
    "    del df['timestamp_aligned']; gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 69.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "weather_train_df = timestamp_align(weather_train_df, temp)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocessWeather(weather_train_df)\n",
    "preprocessWeather_lag(weather_train_df, window=3)\n",
    "#preprocessWeather_lag(weather_train_df, window=12)\n",
    "preprocessWeather_lag(weather_train_df, window=48)\n",
    "#preprocessWeather_lag(weather_train_df, window=72)\n",
    "#preprocessWeather_lag(weather_train_df, window=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df['date'] = train_df['timestamp'].dt.date\n",
    "\n",
    "try:\n",
    "    train_df.drop(index=(rows_to_drop['0']), inplace=True)\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "preprocessDf(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_use_list = building_meta_df['primary_use'].unique()\n",
    "primary_use_dict = {key: value for value, key in enumerate(primary_use_list)}\n",
    "building_meta_df['primary_use'] = building_meta_df['primary_use'].map(primary_use_dict)\n",
    "preprocessBuilding(building_meta_df)\n",
    "del primary_use_list, primary_use_dict; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2842.55 MB\n",
      "Memory usage after optimization is: 1265.40 MB\n",
      "Decreased by 55.5%\n",
      "Memory usage of dataframe is 0.09 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 78.0%\n",
      "Memory usage of dataframe is 78.91 MB\n",
      "Memory usage after optimization is: 43.19 MB\n",
      "Decreased by 45.3%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_mem_usage(train_df, use_float16=True)\n",
    "reduce_mem_usage(building_meta_df, use_float16=True)\n",
    "reduce_mem_usage(weather_train_df, use_float16=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocessDf(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data (Timestamp Alignment & Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weather_test_df = timestamp_align(weather_test_df, temp)\n",
    "preprocessWeather(weather_test_df)\n",
    "preprocessWeather_lag(weather_test_df, window=3)\n",
    "preprocessWeather_lag(weather_test_df, window=12)\n",
    "preprocessWeather_lag(weather_test_df, window=48)\n",
    "preprocessWeather_lag(weather_test_df, window=72)\n",
    "preprocessWeather_lag(weather_test_df, window=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 5209.34 MB\n",
      "Memory usage after optimization is: 2266.66 MB\n",
      "Decreased by 56.5%\n",
      "Memory usage of dataframe is 212.05 MB\n",
      "Memory usage after optimization is: 158.64 MB\n",
      "Decreased by 25.2%\n",
      "Wall time: 7.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "reduce_mem_usage(test_df, use_float16=True)\n",
    "reduce_mem_usage(weather_test_df, use_float16=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['isweekend', 'building_id', 'site_id', 'primary_use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = [\n",
    "    'air_temperature', 'dew_temperature',\n",
    "    'hour_cos', 'hour_sin',\n",
    "    'air_temperature_mean_lag48',\n",
    "    'weekday_sin', 'weekday_cos', 'dayofweek',\n",
    "    'feels_like_temperature', 'square_feet', 'sqft_*_floorcount', 'sqft-x-yearbuilt', 'relative_humidity',\n",
    "    'sea_level_pressure',\n",
    "    'building__mean', 'building__median', 'building__Q3', 'building__Q1', 'building__min', 'building__IQR', 'building__range', 'building__max', 'building__std', 'building__count',\n",
    "    'feels_like_temperature_Q1_lag48', 'feels_like_temperature_max_lag48',\n",
    "    'feels_like_temperature_Q1_lag3', 'feels_like_temperature_max_lag3',\n",
    "    'hour_mean', 'hour_min', 'hour_max', 'hour_std',\n",
    "    'row_na'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTrains(train_df, target_meter):\n",
    "    \n",
    "    target_train_df = train_df[train_df['meter'] == target_meter]\n",
    "    target_train_df = target_train_df.merge(building_meta_df, on='building_id', how='left')\n",
    "    target_train_df = target_train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\n",
    "    \n",
    "    target_train_df['row_na'] = target_train_df.isna().sum(axis=1)\n",
    "    target_train_df['feels_like_temperature'] = np.log1p(target_train_df['feels_like_temperature'])\n",
    "    target_train_df['air_temperature'] = np.log1p(target_train_df['air_temperature'])\n",
    "    target_train_df['dew_temperature'] = np.log1p(target_train_df['dew_temperature'])\n",
    "    \n",
    "    X_train_1 = target_train_df[common_cols + category_cols]\n",
    "    y_train_1 = target_train_df['meter_reading_log1p'].values\n",
    "\n",
    "    df = pd.Series(y_train_1).copy()\n",
    "    temp = np.where(df==0, 0, 1)\n",
    "    df = pd.DataFrame(X_train_1).copy()\n",
    "    del X_train_1['building__min']\n",
    "    \n",
    "    del target_train_df\n",
    "    gc.collect()\n",
    "    return X_train_1, y_train_1, df, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTests(test_df, target_meter, train_df):\n",
    "    \n",
    "    target_test_df = test_df[test_df['meter'] == target_meter]\n",
    "    target_test_df = target_test_df.merge(building_meta_df, on='building_id', how='left')\n",
    "    target_test_df = target_test_df.merge(weather_test_df, on=['site_id', 'timestamp'], how='left')\n",
    "    \n",
    "    target_train_df = train_df[train_df['meter'] == target_meter]\n",
    "    target_train_df = target_train_df.merge(building_meta_df, on='building_id', how='left')\n",
    "    target_train_df = target_train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\n",
    "    target_test_df['row_na'] = target_test_df.isna().sum(axis=1)\n",
    "    target_test_df['feels_like_temperature'] = np.log1p(target_test_df['feels_like_temperature'])\n",
    "    target_test_df['air_temperature'] = np.log1p(target_test_df['air_temperature'])\n",
    "    target_test_df['dew_temperature'] = np.log1p(target_test_df['dew_temperature'])\n",
    "\n",
    "    X_test = target_test_df[common_cols + category_cols]\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_0, y_train_0, x_temp_0, temp_0 = returnTrains(train_df, target_meter=0)\n",
    "X_train_1, y_train_1, x_temp_1, temp_1 = returnTrains(train_df, target_meter=1)\n",
    "X_train_2, y_train_2, x_temp_2, temp_2 = returnTrains(train_df, target_meter=2)\n",
    "X_train_3, y_train_3, x_temp_3, temp_3 = returnTrains(train_df, target_meter=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT (Gradient-Boosting Decision Tree Regression Model): LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitLgbm(train, valid, seed=None,\n",
    "            objective='regression', metric='huber',\n",
    "            cat_features=None, num_rounds=3000, lr=0.3, bf=0.1, ff=0.7, l1=0, reg=2, num=32+16, hessian=1e-3, min_data=20, max_depth=-1):\n",
    "    \n",
    "    X_train, y_train = train\n",
    "    X_valid, y_valid = valid\n",
    "    \n",
    "    params = {'num_leaves': num,\n",
    "              'objective': objective,\n",
    "              'learning_rate': lr,\n",
    "              \"boosting\": \"gbdt\",\n",
    "              \"bagging_freq\": 5,\n",
    "              \"bagging_fraction\": bf,\n",
    "              \"feature_fraction\": ff,\n",
    "              'min_child_weight': hessian,   \n",
    "              'min_data_in_leaf': min_data,\n",
    "              'max_depth': max_depth,\n",
    "              \"metric\": metric,\n",
    "              'reg_alpha': l1,\n",
    "              'reg_lambda': reg,\n",
    "              'verbose': -1}\n",
    "    \n",
    "    params['seed'] = seed\n",
    "    d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n",
    "    d_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_features)\n",
    "    watchlist = [d_train, d_valid]\n",
    "\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist, evals_result=evals_result,\n",
    "                      verbose_eval=500, early_stopping_rounds=20)\n",
    "\n",
    "    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    \n",
    "    log = {'train/mae': model.best_score['training'][f'{metric}'],\n",
    "           'valid/mae': model.best_score['valid_1'][f'{metric}']}\n",
    "    \n",
    "    return model, y_pred_valid, log, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    importance_df = pd.DataFrame(model.feature_importance(),\n",
    "                                 index=common_cols + category_cols,# + temp_cols,\n",
    "                                 columns=['importance']).sort_values('importance')\n",
    "    fig, ax = plt.subplots(figsize=(10, 13))\n",
    "    importance_df.plot.barh(ax=ax)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTest(X_test, models, batch_size=1_000_000):\n",
    "    \n",
    "    iterations = (X_test.shape[0] + batch_size -1) // batch_size\n",
    "    \n",
    "    y_test_pred_total = np.zeros(X_test.shape[0])\n",
    "    for i, model in enumerate(models):\n",
    "        print(f'predicting w/ {i}-th model')\n",
    "        for k in range(iterations):\n",
    "            y_pred_test = model.predict(X_test[k*batch_size:(k+1)*batch_size], num_iteration=model.best_iteration)\n",
    "            y_test_pred_total[k*batch_size:(k+1)*batch_size] += y_pred_test\n",
    "\n",
    "    y_test_pred_total /= len(models)\n",
    "    return y_test_pred_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 2\n",
    "seed = None\n",
    "kf = KFold(n_splits=folds, shuffle=False)\n",
    "tscv = TimeSeriesSplit(n_splits=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 5763682 | valid: 5763683\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's huber: 0.0296853\tvalid_1's huber: 0.0621339\n",
      "train: 5763683 | valid: 5763682\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's huber: 0.0269232\tvalid_1's huber: 0.0605684\n"
     ]
    }
   ],
   "source": [
    "target_meter = 0\n",
    "y_valid_pred_total = np.zeros(X_train_0.shape[0])\n",
    "added_col = ['feels_like_temperature_pct_change_3']\n",
    "\n",
    "models0 = []\n",
    "for train_idx, valid_idx in kf.split(X_train_0, y_train_0):\n",
    "    \n",
    "    train_data = X_train_0.iloc[train_idx,:], y_train_0[train_idx]\n",
    "    valid_data = X_train_0.iloc[valid_idx,:], y_train_0[valid_idx]\n",
    "\n",
    "    print('train:', len(train_idx), '| valid:', len(valid_idx))\n",
    "    model, y_pred_valid, log, evals_result_0 = fitLgbm(train_data, valid_data,\n",
    "                                                       seed=seed,\n",
    "                                                       cat_features=category_cols,\n",
    "                                                       num_rounds=350*5,#*5,\n",
    "                                                       lr=0.05773181964275955,#/5,\n",
    "                                                       bf=0.26796569889874977,\n",
    "                                                       ff=0.3936272203346429,\n",
    "                                                       l1=3.5478121904764905,\n",
    "                                                       reg=28.620086849549573,\n",
    "                                                       num=int(492.6066450470124),\n",
    "                                                       hessian=0.02297650760194559,\n",
    "                                                       min_data=int(167.2740900162622),\n",
    "                                                       max_depth=int(0.642355829229224))\n",
    "    models0.append(model)\n",
    "    gc.collect()\n",
    "    if debug:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = [models0[0].best_score['valid_1']['huber'], models0[1].best_score['valid_1']['huber']]\n",
    "TR = [models0[0].best_score['training']['huber'], models0[1].best_score['training']['huber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1954459 | valid: 1954460\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's huber: 0.126169\tvalid_1's huber: 0.303959\n",
      "train: 1954460 | valid: 1954459\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\ttraining's huber: 0.145252\tvalid_1's huber: 0.293306\n"
     ]
    }
   ],
   "source": [
    "target_meter = 1\n",
    "y_valid_pred_total = np.zeros(X_train_1.shape[0])\n",
    "\n",
    "models1 = []\n",
    "for train_idx, valid_idx in kf.split(X_train_1, y_train_1):\n",
    "    \n",
    "    train_data = X_train_1.iloc[train_idx,:], y_train_1[train_idx]\n",
    "    valid_data = X_train_1.iloc[valid_idx,:], y_train_1[valid_idx]\n",
    "\n",
    "    print('train:', len(train_idx), '| valid:', len(valid_idx))\n",
    "    model, y_pred_valid, log, evals_result_1 = fitLgbm(train_data, valid_data,\n",
    "                                                       seed=seed,\n",
    "                                                       cat_features=category_cols,\n",
    "                                                       num_rounds=235*5,#*5,\n",
    "                                                       lr=0.03777627184627892,#/5,\n",
    "                                                       bf=0.6441781260868563,\n",
    "                                                       ff=0.6715453909673709,\n",
    "                                                       l1=12.015431047748624,\n",
    "                                                       reg=0.5414451954639196,\n",
    "                                                       num=int(425.1833449814948),\n",
    "                                                       hessian=0.02432008332439737,\n",
    "                                                       min_data=int(130.06407988656792),\n",
    "                                                       max_depth=int(0.2769423857727893))\n",
    "    models1.append(model)\n",
    "    gc.collect()\n",
    "    if debug:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.append(models1[0].best_score['valid_1']['huber'])\n",
    "CV.append(models1[1].best_score['valid_1']['huber'])\n",
    "TR.append(models1[0].best_score['training']['huber'])\n",
    "TR.append(models1[1].best_score['training']['huber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1320197 | valid: 1320197\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's huber: 0.235449\tvalid_1's huber: 0.391183\n",
      "train: 1320197 | valid: 1320197\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's huber: 0.22551\tvalid_1's huber: 0.427714\n"
     ]
    }
   ],
   "source": [
    "target_meter = 2\n",
    "y_valid_pred_total = np.zeros(X_train_2.shape[0])\n",
    "\n",
    "models2 = []\n",
    "for train_idx, valid_idx in kf.split(X_train_2, y_train_2):\n",
    "    \n",
    "    train_data = X_train_2.iloc[train_idx,:], y_train_2[train_idx]\n",
    "    valid_data = X_train_2.iloc[valid_idx,:], y_train_2[valid_idx]\n",
    "\n",
    "    print('train:', len(train_idx), '| valid:', len(valid_idx))\n",
    "    model, y_pred_valid, log, evals_result_2 = fitLgbm(train_data, valid_data,\n",
    "                                                       seed=seed,\n",
    "                                                       cat_features=category_cols,\n",
    "                                                       num_rounds=165*5,#*5,\n",
    "                                                       lr=0.08646906661180581,#/5,\n",
    "                                                       bf=0.7189802865959849,\n",
    "                                                       ff=0.7085556468373223,\n",
    "                                                       l1=22.81995553164059,\n",
    "                                                       reg=6.38542313999785,\n",
    "                                                       num=int(451.26369424324986),\n",
    "                                                       hessian=0.39439907915778355,\n",
    "                                                       min_data=int(25.424846207146917),\n",
    "                                                       max_depth=int(24.84006803870966))\n",
    "    models2.append(model)\n",
    "    gc.collect()\n",
    "    if debug:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.append(models2[0].best_score['valid_1']['huber'])\n",
    "CV.append(models2[1].best_score['valid_1']['huber'])\n",
    "TR.append(models2[0].best_score['training']['huber'])\n",
    "TR.append(models2[1].best_score['training']['huber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 576581 | valid: 576582\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's huber: 0.399342\tvalid_1's huber: 0.600572\n",
      "train: 576582 | valid: 576581\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttraining's huber: 0.358418\tvalid_1's huber: 0.6095\n"
     ]
    }
   ],
   "source": [
    "target_meter = 3\n",
    "y_valid_pred_total = np.zeros(X_train_3.shape[0])\n",
    "\n",
    "models3 = []\n",
    "for train_idx, valid_idx in kf.split(X_train_3, y_train_3):\n",
    "    train_data = X_train_3.iloc[train_idx,:], y_train_3[train_idx]\n",
    "    valid_data = X_train_3.iloc[valid_idx,:], y_train_3[valid_idx]\n",
    "\n",
    "    print('train:', len(train_idx), '| valid:', len(valid_idx))\n",
    "    model, y_pred_valid, log, evals_result_3 = fitLgbm(train_data, valid_data,\n",
    "                                                       seed=seed,\n",
    "                                                       cat_features=category_cols,\n",
    "                                                       num_rounds=175*5,#*5,\n",
    "                                                       lr=0.12281564370554858,#/5,\n",
    "                                                       bf=0.8421331995739937,\n",
    "                                                       ff=0.28732134167029566,\n",
    "                                                       l1=1.510625394641553,\n",
    "                                                       reg=25.660908491738372,\n",
    "                                                       num=int(28.514072092238653),\n",
    "                                                       hessian=0.036216698203522454,\n",
    "                                                       min_data=int(21.61115352418879),\n",
    "                                                       max_depth=int(31.719112307783114))\n",
    "    models3.append(model)\n",
    "    gc.collect()\n",
    "    if debug:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.append(models3[0].best_score['valid_1']['huber'])\n",
    "CV.append(models3[1].best_score['valid_1']['huber'])\n",
    "TR.append(models3[0].best_score['training']['huber'])\n",
    "TR.append(models3[1].best_score['training']['huber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meter0: CVbar: 0.06135112777600039. TRbar: 0.028304226044513166\n",
      "meter1: CVbar: 0.2986326935039836. TRbar: 0.13571045126706535\n",
      "meter2: CVbar: 0.40944859533243094. TRbar: 0.23047992520925667\n",
      "meter3: CVbar: 0.6050358110063654. TRbar: 0.3788802606388617\n",
      "Cross Validation Score: 0.19333727018954966\n"
     ]
    }
   ],
   "source": [
    "print('meter0: CVbar: {}. TRbar: {}'.format(np.mean(CV[:2]), np.mean(TR[:2])))\n",
    "print('meter1: CVbar: {}. TRbar: {}'.format(np.mean(CV[2:4]), np.mean(TR[2:4])))\n",
    "print('meter2: CVbar: {}. TRbar: {}'.format(np.mean(CV[4:6]), np.mean(TR[4:6])))\n",
    "print('meter3: CVbar: {}. TRbar: {}'.format(np.mean(CV[6:]), np.mean(TR[6:])))\n",
    "temp = np.mean(CV[:2]) * (11714696 / 19869886)\n",
    "temp += np.mean(CV[2:4]) * (4182440 / 19869886)\n",
    "temp += np.mean(CV[4:6]) * (2708713 / 19869886)\n",
    "temp += np.mean(CV[6:]) * (1264037 / 19869886)\n",
    "print(\"Cross Validation Score: {}\".format(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating meter #0 test data\n",
      "predicting w/ 0-th model\n",
      "predicting w/ 1-th model\n",
      "Generating meter #1 test data\n",
      "predicting w/ 0-th model\n",
      "predicting w/ 1-th model\n",
      "Generating meter #2 test data\n",
      "predicting w/ 0-th model\n",
      "predicting w/ 1-th model\n",
      "Generating meter #3 test data\n",
      "predicting w/ 0-th model\n",
      "predicting w/ 1-th model\n"
     ]
    }
   ],
   "source": [
    "y_test = {}\n",
    "for i in range(4):\n",
    "    print(f'Generating meter #{i} test data')\n",
    "    X_test = returnTests(test_df, target_meter=i, train_df=train_df)\n",
    "    del X_test['building__min']\n",
    "    y_test[i] = np.expm1(predictTest(X_test, models0))\n",
    "    del X_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 198.83 MB\n",
      "Decreased by 68.7%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>194.289928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>87.892822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.588913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>317.116782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1326.458052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697595</th>\n",
       "      <td>41697595</td>\n",
       "      <td>6.424563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697596</th>\n",
       "      <td>41697596</td>\n",
       "      <td>4.249002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697597</th>\n",
       "      <td>41697597</td>\n",
       "      <td>6.953852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697598</th>\n",
       "      <td>41697598</td>\n",
       "      <td>184.757973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697599</th>\n",
       "      <td>41697599</td>\n",
       "      <td>3.740043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  meter_reading\n",
       "0                0     194.289928\n",
       "1                1      87.892822\n",
       "2                2       9.588913\n",
       "3                3     317.116782\n",
       "4                4    1326.458052\n",
       "...            ...            ...\n",
       "41697595  41697595       6.424563\n",
       "41697596  41697596       4.249002\n",
       "41697597  41697597       6.953852\n",
       "41697598  41697598     184.757973\n",
       "41697599  41697599       3.740043\n",
       "\n",
       "[41697600 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "reduce_mem_usage(sample_submission)\n",
    "\n",
    "for i in range(4):\n",
    "    sample_submission.loc[test_df['meter'] == i, 'meter_reading'] = y_test[i]\n",
    "\n",
    "sample_submission['meter_reading'] = sample_submission['meter_reading'].clip(lower=0)\n",
    "display(sample_submission)\n",
    "# sample_submission.to_csv(name, index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
